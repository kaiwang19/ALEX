 check max_data_node_slots 4 max_fanout 8 KEY_TYPE 8 PAYLOAD_TYPE 8
Build temporary rough root model -> root_node_->model_.a_ 0.166667 root_node_->model_.b_ -0
 build_model with 4 keys. 
compute_expected_cost  avg_exp_search 0 avg_shifts 0 cost 0
Compute cost of root node 0
 ==== Compute_level -> level 1 fanout 2 a 0.333333 b -0
 build_model with 2 keys. 
compute_expected_cost  avg_exp_search 0 avg_shifts 0 cost 0
Compute_level -> total_cost 0 node_cost 0 left_bound 0 right_bound 2 num_keys 4
 build_model with 2 keys. 
compute_expected_cost  avg_exp_search 0 avg_shifts 0 cost 0
Compute_level -> total_cost 0 node_cost 0 left_bound 2 right_bound 4 num_keys 4
Compute_level -> total_cost 10.0004 traversal_cost 10.0004 kNodeLookupsWeight 10 kModelSizeWeight 1e-06 sizeof(AlexDataNode<T, P>) 208 sizeof(void*) 8 fanout 2 total_keys 4 num_keys 4
 ==== Compute_level -> level 2 fanout 4 a 0.666667 b -0
 build_model with 1 keys. 
compute_expected_cost  avg_exp_search 0 avg_shifts 0 cost 0
Compute_level -> total_cost 0 node_cost 0 left_bound 0 right_bound 1 num_keys 4
 build_model with 1 keys. 
compute_expected_cost  avg_exp_search 0 avg_shifts 0 cost 0
Compute_level -> total_cost 0 node_cost 0 left_bound 1 right_bound 2 num_keys 4
 build_model with 1 keys. 
compute_expected_cost  avg_exp_search 0 avg_shifts 0 cost 0
Compute_level -> total_cost 0 node_cost 0 left_bound 2 right_bound 3 num_keys 4
 build_model with 1 keys. 
compute_expected_cost  avg_exp_search 0 avg_shifts 0 cost 0
Compute_level -> total_cost 0 node_cost 0 left_bound 3 right_bound 4 num_keys 4
Compute_level -> total_cost 10.0009 traversal_cost 10.0009 kNodeLookupsWeight 10 kModelSizeWeight 1e-06 sizeof(AlexDataNode<T, P>) 208 sizeof(void*) 8 fanout 4 total_keys 4 num_keys 4

Using a fanout tree -  best_fanout_tree_depth 0 best_fanout_tree_cost 10
 ==== Compute_level -> level 1 fanout 2 a 0.333333 b -0
 build_model with 2 keys. 
compute_expected_cost  avg_exp_search 0 avg_shifts 0 cost 0
Compute_level -> total_cost 0 node_cost 0 left_bound 0 right_bound 2 num_keys 4
 build_model with 2 keys. 
compute_expected_cost  avg_exp_search 0 avg_shifts 0 cost 0
Compute_level -> total_cost 0 node_cost 0 left_bound 2 right_bound 4 num_keys 4
Compute_level -> total_cost 10.0004 traversal_cost 10.0004 kNodeLookupsWeight 10 kModelSizeWeight 1e-06 sizeof(AlexDataNode<T, P>) 208 sizeof(void*) 8 fanout 2 total_keys 4 num_keys 4

When the model node is out, Instantiate all the child nodes and recurse.

 ++++ bulk_load_node data node  level 1 keys 2 cost 0 data_node_model->a 0.5 b 0 node->a 0.75 b 0 dup 0
 ++++ bulk_load_node data node  level 1 keys 2 cost 0 data_node_model->a 0.5 b -2 node->a 0.75 b -3 dup 0
 $$$$ bulk_load_node model node level 0 num_children 2 a 0.333333 b -0
 ==== After bulk load 
 num_model_nodes 1 num_data_nodes 2 -->  [root node] a_ 0.333333 b_ -0
 level 1 num_keys 2 bitmap 3 capacity 3 size 56 first_key 0 first_pos 0 last_key 2 last_pos 1 a 0.75 b 0
 level 1 num_keys 2 bitmap 3 capacity 3 size 56 first_key 4 first_pos 0 last_key 6 last_pos 1 a 0.75 b -3

 ---> Check if node is full  num_keys_2 expansion_threshold_3
 ==== ready for insert key 1
 ffuu exponential_search_upper_bound key 1 m 0 bound 1 l 0 r 1
 ==== exponential_search_upper_bound key 1 predicted_pos 0 pos 1
 ==== insert_using_shifts  key 1 pos 1 gap_pos 2
 ==== insert_using_shifts  key 1 insertion_position 1
 ==== try insert  key 1 fail 0 insert_pos 1
 ==== After inserting 1 keys: 1
 num_model_nodes 1 num_data_nodes 2 -->  [root node] a_ 0.333333 b_ -0
 level 1 num_keys 3 bitmap 7 capacity 3 size 56 first_key 0 first_pos 0 last_key 2 last_pos 2 a 0.75 b 0
 level 1 num_keys 2 bitmap 3 capacity 3 size 56 first_key 4 first_pos 0 last_key 6 last_pos 1 a 0.75 b -3

 ---> Check if node is full  num_keys_3 expansion_threshold_3
 ==== try insert  key 2 fail 3 insert_pos -1
 ==== after fail  fanout_tree_depth 1
 ==== split_sideways  fanout 2 repeats 1
 **** Internal Node expansion: expansion_factor 2, this->model_.a_ 0.333333, this->model_.b_ -0
 **** After Internal Node expansion: expansion_factor 2, this->model_.a_ 0.666667, this->model_.b_ -0
 ==== create_two_new_data_nodes with empty used_fanout_tree_nodes fanout 2 repeats 2
 ffll exponential_search_lower_bound key 1.5 m 0 bound 2 l 1 r 2
compute_expected_cost  avg_exp_search 0 avg_shifts 0.5 cost 0.25
compute_expected_cost  avg_exp_search 0 avg_shifts 0 cost 0
 ---> Check if node is full  num_keys_1 expansion_threshold_2
 ==== ready for insert key 2
 ffuu exponential_search_upper_bound key 2 m 0 bound 1 l 0 r 1
 ==== exponential_search_upper_bound key 2 predicted_pos 0 pos 1
 ==== insert_element_at  key 2 insertion_position 1
 ==== After inserting 2 keys: 2
 num_model_nodes 1 num_data_nodes 3 -->  [root node] a_ 0.666667 b_ -0
 level 1 num_keys 2 bitmap 3 capacity 3 size 56 first_key 0 first_pos 0 last_key 1 last_pos 1 a 0.9375 b 0.5
 level 1 num_keys 2 bitmap 3 capacity 2 size 40 first_key 2 first_pos 0 last_key 2 last_pos 1 a 1.5 b -4
 level 1 num_keys 2 bitmap 3 capacity 3 size 56 first_key 4 first_pos 0 last_key 6 last_pos 1 a 0.75 b -3

 ---> Check if node is full  num_keys_2 expansion_threshold_3
 ==== ready for insert key 3
 ffuu exponential_search_upper_bound key 3 m 0 bound 1 l 0 r 0
 ==== exponential_search_upper_bound key 3 predicted_pos 0 pos 0
 ==== insert_using_shifts  key 3 pos 0 gap_pos 2
 ==== insert_using_shifts  key 3 insertion_position 0
 ==== try insert  key 3 fail 0 insert_pos 0
 ==== After inserting 3 keys: 3
 num_model_nodes 1 num_data_nodes 3 -->  [root node] a_ 0.666667 b_ -0
 level 1 num_keys 2 bitmap 3 capacity 3 size 56 first_key 0 first_pos 0 last_key 1 last_pos 1 a 0.9375 b 0.5
 level 1 num_keys 2 bitmap 3 capacity 2 size 40 first_key 2 first_pos 0 last_key 2 last_pos 1 a 1.5 b -4
 level 1 num_keys 3 bitmap 7 capacity 3 size 56 first_key 3 first_pos 0 last_key 6 last_pos 2 a 0.75 b -3

 ---> Check if node is full  num_keys_3 expansion_threshold_3
 ==== try insert  key 4 fail 3 insert_pos -1
 ==== after fail  fanout_tree_depth 1
 ==== split_sideways  fanout 2 repeats 2
 ==== create_two_new_data_nodes with empty used_fanout_tree_nodes fanout 2 repeats 2
 ffll exponential_search_lower_bound key 4.5 m 0 bound 2 l 1 r 2
compute_expected_cost  avg_exp_search 0.5 avg_shifts 0.5 cost 5.25
compute_expected_cost  avg_exp_search 0 avg_shifts 0 cost 0
 ---> Check if node is full  num_keys_2 expansion_threshold_3
 ==== ready for insert key 4
 ffuu exponential_search_upper_bound key 4 m 0 bound 2 l 1 r 2
 ==== exponential_search_upper_bound key 4 predicted_pos 0 pos 2
 ==== insert_element_at  key 4 insertion_position 2
 ==== After inserting 4 keys: 4
 num_model_nodes 1 num_data_nodes 4 -->  [root node] a_ 0.666667 b_ -0
 level 1 num_keys 2 bitmap 3 capacity 3 size 56 first_key 0 first_pos 0 last_key 1 last_pos 1 a 0.9375 b 0.5
 level 1 num_keys 2 bitmap 3 capacity 2 size 40 first_key 2 first_pos 0 last_key 2 last_pos 1 a 1.5 b -4
 level 1 num_keys 3 bitmap 7 capacity 3 size 56 first_key 3 first_pos 0 last_key 4 last_pos 2 a 0.9375 b -3.25
 level 1 num_keys 1 bitmap 1 capacity 2 size 40 first_key 6 first_pos 0 last_key 6 last_pos 0 a 1.5 b -10

 ---> Check if node is full  num_keys_1 expansion_threshold_2
 ==== ready for insert key 7
 ffuu exponential_search_upper_bound key 7 m 0 bound 1 l 0 r 1
 ==== exponential_search_upper_bound key 7 predicted_pos 0 pos 1
 ==== insert_element_at  key 7 insertion_position 1
 ==== try insert  key 7 fail 0 insert_pos 1
 ==== After inserting 5 keys: 7
 num_model_nodes 1 num_data_nodes 4 -->  [root node] a_ 0.666667 b_ -0
 level 1 num_keys 2 bitmap 3 capacity 3 size 56 first_key 0 first_pos 0 last_key 1 last_pos 1 a 0.9375 b 0.5
 level 1 num_keys 2 bitmap 3 capacity 2 size 40 first_key 2 first_pos 0 last_key 2 last_pos 1 a 1.5 b -4
 level 1 num_keys 3 bitmap 7 capacity 3 size 56 first_key 3 first_pos 0 last_key 4 last_pos 2 a 0.9375 b -3.25
 level 1 num_keys 2 bitmap 3 capacity 2 size 40 first_key 6 first_pos 0 last_key 7 last_pos 1 a 1.5 b -10

 ---> Check if node is full  num_keys_2 expansion_threshold_2
 ==== ready for resize
**** Resize: target_density 0.6, force_retrain 0, keep_left 1, keep_right 1
 ==== Before resize update expansion_threshold_  expansion_threshold_2 data_capacity_3 num_keys_2
 ==== After resize update expansion_threshold_  expansion_threshold_3 data_capacity_3 num_keys_2
 ==== ready for insert key 8
 ffuu exponential_search_upper_bound key 8 m 2 bound 1 l 1 r 2
 ==== exponential_search_upper_bound key 8 predicted_pos 2 pos 2
 ==== insert_element_at  key 8 insertion_position 2
 ==== try insert  key 8 fail 0 insert_pos 2
 ==== After inserting 6 keys: 8
 num_model_nodes 1 num_data_nodes 4 -->  [root node] a_ 0.666667 b_ -0
 level 1 num_keys 2 bitmap 3 capacity 3 size 56 first_key 0 first_pos 0 last_key 1 last_pos 1 a 0.9375 b 0.5
 level 1 num_keys 2 bitmap 3 capacity 2 size 40 first_key 2 first_pos 0 last_key 2 last_pos 1 a 1.5 b -4
 level 1 num_keys 3 bitmap 7 capacity 3 size 56 first_key 3 first_pos 0 last_key 4 last_pos 2 a 0.9375 b -3.25
 level 1 num_keys 3 bitmap 7 capacity 3 size 56 first_key 6 first_pos 0 last_key 8 last_pos 2 a 1 b -6

 ---> Check if node is full  num_keys_3 expansion_threshold_3
 ==== try insert  key 9 fail 3 insert_pos -1
 ==== after fail  fanout_tree_depth 1
 ==== split_sideways  fanout 2 repeats 1
 **** Internal Node expansion: expansion_factor 2, this->model_.a_ 0.666667, this->model_.b_ -0
 **** After Internal Node expansion: expansion_factor 2, this->model_.a_ 1.33333, this->model_.b_ -0
 ==== create_two_new_data_nodes with empty used_fanout_tree_nodes fanout 2 repeats 2
 ffll exponential_search_lower_bound key 5.25 m 0 bound 1 l 0 r 0
compute_expected_cost  avg_exp_search 0 avg_shifts 0.666667 cost 0.444444
 ---> Check if node is full  num_keys_3 expansion_threshold_4
 ==== ready for insert key 9
 ffuu exponential_search_upper_bound key 9 m 3 bound 1 l 2 r 3
 ==== exponential_search_upper_bound key 9 predicted_pos 3 pos 3
 ==== insert_element_at  key 9 insertion_position 3
 ==== After inserting 7 keys: 9
 num_model_nodes 1 num_data_nodes 5 -->  [root node] a_ 1.33333 b_ -0
 level 1 num_keys 2 bitmap 3 capacity 3 size 56 first_key 0 first_pos 0 last_key 1 last_pos 1 a 0.9375 b 0.5
 level 1 num_keys 2 bitmap 3 capacity 2 size 40 first_key 2 first_pos 0 last_key 2 last_pos 1 a 1.5 b -4
 level 1 num_keys 3 bitmap 7 capacity 3 size 56 first_key 3 first_pos 0 last_key 4 last_pos 2 a 0.9375 b -3.25
 level 1 num_keys 0 bitmap 0 capacity 1 size 24 first_key 18446744073709551615 first_pos 0 last_key 0 last_pos 0 a nan b nan
 level 1 num_keys 4 bitmap 15 capacity 5 size 88 first_key 6 first_pos 0 last_key 9 last_pos 3 a 1.25 b -7.5

 ---> Check if node is full  num_keys_4 expansion_threshold_4
 ==== try insert  key 10 fail 3 insert_pos -1
 ==== after fail  fanout_tree_depth 1
 $$$$ After split_downwards  level_ 1 duplication_factor_ 0 num_children_ 2 model_.a_ 2.66667 model_.b_ -14
 ffll exponential_search_lower_bound key 5.625 m 0 bound 1 l 0 r 0
compute_expected_cost  avg_exp_search 0 avg_shifts 1 cost 0.5
 ---> Check if node is full  num_keys_4 expansion_threshold_5
 ==== ready for insert key 10
 ffuu exponential_search_upper_bound key 10 m 5 bound 2 l 3 r 4
 ==== exponential_search_upper_bound key 10 predicted_pos 5 pos 4
 ==== insert_element_at  key 10 insertion_position 5
 ==== After inserting 8 keys: 10
 num_model_nodes 2 num_data_nodes 6 -->  [root node] a_ 1.33333 b_ -0
 level 1 num_keys 2 bitmap 3 capacity 3 size 56 first_key 0 first_pos 0 last_key 1 last_pos 1 a 0.9375 b 0.5
 level 1 num_keys 2 bitmap 3 capacity 2 size 40 first_key 2 first_pos 0 last_key 2 last_pos 1 a 1.5 b -4
 level 1 num_keys 3 bitmap 7 capacity 3 size 56 first_key 3 first_pos 0 last_key 4 last_pos 2 a 0.9375 b -3.25
 level 1 num_keys 0 bitmap 0 capacity 1 size 24 first_key 18446744073709551615 first_pos 0 last_key 0 last_pos 0 a nan b nan
 level 2 num_keys 0 bitmap 0 capacity 1 size 24 first_key 18446744073709551615 first_pos 0 last_key 0 last_pos 0 a nan b nan
 level 2 num_keys 5 bitmap 47 capacity 6 size 104 first_key 6 first_pos 0 last_key 10 last_pos 5 a 1.25 b -7.5

